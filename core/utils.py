from services.chatgpt.client import ChatGPT
from core.constants import CATEGORIES, ALL_DIFFICULTY_LEVELS

def generate_interview_questions(
        resume_details: str,
        job_description: str,
        categories: list = ["Technical"],
        difficulty_level: str = "Medium",
        n: int = 1) -> list:
    """Generate Interview Questions based on JD and Resume Details

    Args:
        resume_details (str): resume details
        job_description (str): job description
        categories (list): lits of categories like ["Technical", "Behavioral", "Communication".. ect] or "All"
        difficulty_level (str): Easy, Medium, Advanced or All, defaults to Easy
        n (int): Number of response want to generate, defaults to 1

    Returns:
        list: list of responses generated by chatgpt
    """
    prompt = ""
    candidate_details = f"Candidate Info:- {resume_details}\n\n"
    job_details = f"Job Description:- {job_description}\n\n"
    if difficulty_level == "All":
        difficulty_level = ALL_DIFFICULTY_LEVELS
    if categories == "All":
        categories = CATEGORIES
    if candidate_details:
        prompt += candidate_details
    if job_details:
        prompt += job_details
    base_prompt = f"""Based on Above Candidate Info and Job Description, generate 10 {difficulty_level} Interview Questions
    that tests candidate's {", ".join(categories)} skills. You have to create those questions skill wise.
    """
    final_prompt = prompt + base_prompt
    breakpoint()
    chatgpt = ChatGPT(prompt=final_prompt, n=n)
    answers = chatgpt.get_answers()

    return answers


#TODO: For Testing; we can remove this later
resume = """
CORE COMPETENCIES
Proficient in utilising Python (Django and Flask) to create and deploy cloud-based solutions.
Skilled in developing back-end components that enhance performance and responsiveness, and the ability to produce quality code with unit tests. also capable of maintaining code by resolving issues and improving app performance.
Convert client requirements into technical solutions by understanding their business and functional requirements.
Ability to write quality code with unit tests and maintain code by fixing bugs and improving app performance.
Proficient in Agile, Scrum, and Waterfall methodologies, which enable efficient and streamlined development processes.
Knowledgeable in system integration and capable of integrating with other microservices and third-party platforms
An experienced team player who provides guidance to developers in fast-paced development environments and addresses their technical questions.
SKILLS
Technologies
Python, Django, Flask, JavaScript, jQuery, REST API
Databases
PostgreSQL, Redis, MySQL, SQL server
Libraries

Cloud Services 

Architectures
Celery, Celery-Beat, Scrapy, BeautifulSoup, Pytest, Requests, NumPy, Pandas, SQLAlchemy, boto3
AWS Glue, AWS EC2, AWS Lambda, AWS Textract, API Gateway,AWS S3, CloudWatch,, SQS, SNS, SES, EventBridge, RDS, AWS Quicksight
Monolithic, Microservices, Multi-Tenant Architecture
Version Control
GitHub, Bitbucket, AWS CodeCommit
Tools and Utilities
Docker, Stripe API, Twitter APIs, PubNub APIs, The Trade Desk APIs, Twilio, Datadog
Project management
Zoho, Trello, Slack, JIRA


RECENT PROJECTS
NEWS ARTICLES CRAWLERS
Project Brief: A web scraping solution that retrieves news article data from over 50 websites across various countries, including India, Japan, Brazil, Germany, Canada, Italy, France, China, and more. The data is stored on the cloud, and the system periodically runs scripts to collect new data as well as historical data within a specific time period. Using data analytics and machine learning models, the system utilizes this data to provide valuable insights, helpful information, and notifications to its customers. 
Technology Stack: Python, boto3, AWS S3, Scrapy, BeautifulSoup, Selenium

FLEET MANAGEMENT SOLUTION
Project Brief: A comprehensive fleet management platform that enables businesses to keep track of their vehicles, assets, and users across multiple fleets and customers. The platform appears to provide a range of useful features, including the ability to view historical data and track incident trends, as well as identify top drivers and fleet routes. The ability to create custom reports and receive notifications via email or SMS based on user preferences can also be incredibly valuable for businesses looking to optimize their operations and improve their overall efficiency.
Technology Stack: Django REST Framework, Celery, Celery-Beat, Redis, PostgreSQL, AWS Lambda, RDS, EC2, S3, SES, Docker, CloudWatch, Multi-tenant architecture, Datadog


SCHOOL ANALYTICS SYSTEM
Project Brief: A data analytics platform that gathers information on the daily activities of students and conducts ETL (Extract, Transform, Load) processes to manipulate the data. By generating individual analytics and graphs for each student, the platform enables school management to obtain valuable insights into student performance and progress. Worked with PySpark for doing distributed computation. 
Technology Stack: AWS Glue, Python, PostgreSQL, PySpark Library, Amazon S3, AWS EC2, Lambda, RDS, Slack Integration

SOCIAL MEDIA ANALYTICS
Project Brief: A social media analytics platform that extracts tweets containing polls from prominent cancer specialist doctors via APIs. The extracted data is displayed on a dashboard with a ranking feature. Lambda functions have been created to fetch historic and periodic tweets every 2 hours, process them, and store the data on S3 and a PostgreSQL database on RDS. In order to prevent Lambda function timeouts and decrease running time, database performance tuning techniques have been implemented.
Technology Stack:- AWS Lambda, PostgreSQL, Amazon S3, AWS EventBridge, Secrets Manager """



job_description = """About Client -> Lanterne is an award-winning data science and geospatial analytics company based in the UK, Europe, and Australia.
Skills Set they are looking for: In this role you will get to understand, design, develop, test, maintain and improve our codebase, composed of multiple backend services, tools for accomplishing core tasks and a web application.

The backend services and tools are developed using Python combined with various tools (e.g. Poetry) and libraries (e.g. mypy, pytest).
The web application is developed using React.js.
The responsibilities of the backend services and tools are varied and include some very interesting algorithms. Some of the more interesting ones that could be shortly explained are: ETL and machine learning services or tools, and the vehicle routing solver.
The backend is built using an AWS cloud native backend microservices architecture. Some of the services we use are: Lambda, S3, DynamoDB, Step Functions, Glue, and ECS.
Current dev ops and developer productivity processes and tools: CloudFormation, AWS SAM, ECR, SNS, AppConfig, and Amplify."""

generate_interview_questions(resume, job_description, categories=["Technical"], difficulty_level="All", n=1)
